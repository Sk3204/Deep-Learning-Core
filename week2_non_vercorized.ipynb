{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJOd+Zo6Th7J43JLqDgB3K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sk3204/Deep-Learning-Core/blob/main/week2_non_vercorized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NEURAL NETWORK"
      ],
      "metadata": {
        "id": "3-FltHEq2rhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction"
      ],
      "metadata": {
        "id": "2KUpCX_JXP36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Neural Network**:\n",
        "  * Interconnected nodes that compute together to give output based on input\n",
        "  * Tries to mimic human brain\n",
        "  * Structure:Built in layers(Input-> Hidden -> Output)\n",
        "  * Node(Neuron): Does specific calculation(Weighted Sum)\n",
        "  * Weights:Tells the importance of each connection\n",
        "  * Bias:Constant value added to node to fit pattern\n",
        "  * Activation Function(Mathematical Filter/Function):Transforms the node's raw calculation into a refined output value to easily represent complex data patterns\n",
        "  * Training:Process of automatically adjusting Weights and Biases to reduce errors.\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "diyo4kso2_Zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Network Types:**\n",
        "* **ANN**:feedforward NN,simplest form,information moves in only 1 direction(input to output)\n",
        "  * Best for:Tabular data,simple regression and classification task.\n",
        "* **CNN**:kings of computer vision,use \"filters\" to scan images for patterns\n",
        "  * Best for image recognition,medical imaging\n",
        "* **RNN**:designed for data that comes in a sequence where order matters.contains memory\n",
        "  * Best for speech recognition,and NLP\n",
        "* **GAN**:GAN combination of 2 network.Generator tries to create fake data Discriminator tries to catch the fake data.\n",
        "  * Best for:Creating \"deepfakes\",\"generating art\n",
        "* **Transformers**:uses Self-Attention mechanism to look at entire sentence at once understanding the context of every word simulataneously\n",
        "  * Best for LLMs,translation,complex text generation."
      ],
      "metadata": {
        "id": "UXI3MeNdIcf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data types:**\n",
        "* Structured Data:Tables including features and outputs\n",
        "* Unstructured Data:Audio,Image,Text"
      ],
      "metadata": {
        "id": "7YyeaVmAK_M4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Deep learning boom at present?**\n",
        "* Abundant labelled data due to digitalization and improved devices(mobile,camera etc)\n",
        "* Bigger neural network introduced (more hidden layers,more parameters)\n",
        "* Hardware upgrade and innovation(GPU,TPU)\n",
        "* Algorithm upgrade and innovation:Various algoritm innovation has helped computation and even small thing like switching from sigmoid to relu function has also impacted and made computation faster."
      ],
      "metadata": {
        "id": "sirTWGlpLlKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import math"
      ],
      "metadata": {
        "id": "hoa4YxuuH8sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_breast_cancer()\n"
      ],
      "metadata": {
        "id": "Q9bk8YWCN7L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating dummy data (100 samples, 2 features)\n",
        "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n",
        "# Spliting Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "Mdjdq60BGI3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_Lu-lZv2OFKu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "72dec2cc-2455-43e2-88b4-ba473ee93833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Binary Classification:**\n",
        "* Classification of object as binary digit\n",
        "* Eg:1(cat) vs 0(non cat)\n"
      ],
      "metadata": {
        "id": "sZ6GfRc5aKwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#all the rows but only second column i.e probability of class 1\n",
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "#if probs >0.5 it becomes true and astype makes true=1\n",
        "predictions = (probs > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "WrCuFOOaFlmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Probabilities (first 5): {probs[:5].round(3)}\")\n",
        "print(f\"Binary Classified Output (first 5): {predictions[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNAHJR6CHvxQ",
        "outputId": "401c8ace-765d-411e-fd03-16048aaddc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities (first 5): [0.159 0.001 0.676 0.939 0.978]\n",
            "Binary Classified Output (first 5): [0 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "storing image in creates 3 matrix of blue red green matrix of same dimension containing the pixel intensity.\n",
        "\n",
        "This three matrix are placed one after another in a column matrix as an input in."
      ],
      "metadata": {
        "id": "aC2gvI5zeMJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Notation**\n",
        "\n",
        "Single training example:(x,y)\n",
        "* $$x \\in \\mathbb{R}^{n_x}$$$$y \\in \\{0, 1\\}$$\n",
        "\n",
        "m training examples:\n",
        "* $$\\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\dots, (x^{(m)}, y^{(m)})\\}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "KtDfHTGreVVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "X.shape=(nx,m)\n",
        "\n",
        "Y.shape=(1,m)"
      ],
      "metadata": {
        "id": "n2NE9hA6hUIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Demo Initializing/Self Created\n",
        "nx = 3  # features (e.g., age, weight, member_status)\n",
        "m = 2   # training examples\n",
        "\n",
        "w=np.zeros(nx)                    #Shape:(nx,1)\n",
        "b=0                               #Shape:(1,)\n",
        "X = np.array([                    #Shape:(nx,m)\n",
        "    [10, 20],  # Feature 1 (e.g., Age)\n",
        "    [ 5,  8],  # Feature 2 (e.g., Weight)\n",
        "    [ 1,  0]   # Feature 3 (e.g., Member_Status)\n",
        "])\n",
        "Y = np.array([[1, 0]])            #Shape:(1,m)\n"
      ],
      "metadata": {
        "id": "YGhTht_0hY1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Real dataset\n",
        "X = dataset.data.T               #(m,nx) transposed->(nx,m)\n",
        "Y = dataset.target.reshape(1, -1)# (m,1)-> (1,m)\n",
        "\n",
        "nx, m = X.shape       #features and no of examples\n",
        "w = np.random.randn(nx, 1) * 0.01 #weights #Shape:(nx,1)\n",
        "b = 0                 #biases #Shape:(1,)\n",
        "y_hat=np.zeros((1,m)) #probability container\n",
        "print(f\"Dataset Loaded: Breast Cancer Wisconsin\")\n",
        "print(f\"Features (nx): {nx}\")\n",
        "print(f\"Examples (m): {m}\")\n",
        "print(f\"X shape: {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjHJBm8tRi7C",
        "outputId": "55c12b19-d164-4a6a-bdc0-d3028f35b3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded: Breast Cancer Wisconsin\n",
            "Features (nx): 30\n",
            "Examples (m): 569\n",
            "X shape: (30, 569)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression:"
      ],
      "metadata": {
        "id": "8GMkZd6liM2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computation: $z = w^T X + b$\n",
        "\n",
        "$w^T$ shape $(1, n_x);  $$X$ shape $(n_x, m)$\n",
        "\n",
        "Activation function (Sigmoid): $a = \\sigma(z)$\n",
        "\n",
        "Sigmoid:$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
        "\n",
        "Domain of $z$: $(-\\infty, \\infty)$ — Any real number.\n",
        "\n",
        "Range of $a$ (Activation): $(0, 1)$ — Always stays between 0 and 1.\n",
        "\n",
        "$$a = P(y=1 | x)$$\n",
        "\n",
        "1=100% safe   \n",
        "0=100% unsafe\n"
      ],
      "metadata": {
        "id": "lsUpIu3yYusG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If $z$ is a large positive number, $\\sigma(z) \\approx 1$.\n",
        "\n",
        "If $z$ is a large negative number, $\\sigma(z) \\approx 0$.\n",
        "\n",
        "If $z = 0$, then $\\sigma(z) = 0.5$."
      ],
      "metadata": {
        "id": "IaKb-ZpzZeGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Activation function\n",
        "def sigmoid(z):\n",
        "    # Brings z value in the range betn 0 and 1\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "5JKYd4m5l6Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_prop(X,w,b,m,nx):\n",
        "  y_hat = np.zeros((1, m))\n",
        "  for i in range(m):\n",
        "    # Calculating linear sum for this specific example\n",
        "    z_i = 0\n",
        "    for j in range(nx):\n",
        "        # Multiplying each feature by its weight\n",
        "        z_i += w[j,0] * X[j, i]\n",
        "    z_i += b\n",
        "    # calculating probability\n",
        "    y_hat[0,i] = sigmoid(z_i)\n",
        "  return y_hat"
      ],
      "metadata": {
        "id": "sk7Ne1HhIjWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of output y_hat: {y_hat.shape}\")\n",
        "print(f\"First 5 probabilities: {y_hat[0, :5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YjIR-fmR9-C",
        "outputId": "7d2a649f-f25e-4e1a-fecf-12f7186db93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of output y_hat: (1, 569)\n",
            "First 5 probabilities: [0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"'High Risk / Malignant' Patient (Prob < 0.5) ---\")\n",
        "count = 0\n",
        "for i in range(m):\n",
        "    # y_hat[0, i] :probability for ith patient\n",
        "    if y_hat[0, i] < 0.9:\n",
        "        #print(f\"Patient {i}: Probability = {y_hat[0, i]:.4f}\")\n",
        "        count += 1\n",
        "\n",
        "if count == 0:\n",
        "    print(\"No patients found with probability less than 0.5 with current weights.\")\n",
        "else:\n",
        "    print(f\"\\nTotal high-risk patients found: {count} out of {m}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-UJxyOcTC_-",
        "outputId": "d1a70227-71cf-49a1-a148-521816fff1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'High Risk / Malignant' Patient (Prob < 0.5) ---\n",
            "Patient 0: Probability = 0.0000\n",
            "Patient 1: Probability = 0.0000\n",
            "Patient 2: Probability = 0.0000\n",
            "Patient 3: Probability = 0.0000\n",
            "Patient 4: Probability = 0.0000\n",
            "Patient 5: Probability = 0.0000\n",
            "Patient 6: Probability = 0.0000\n",
            "Patient 7: Probability = 0.0000\n",
            "Patient 8: Probability = 0.0000\n",
            "Patient 9: Probability = 0.0000\n",
            "Patient 10: Probability = 0.0000\n",
            "Patient 11: Probability = 0.0000\n",
            "Patient 12: Probability = 0.0000\n",
            "Patient 13: Probability = 0.0000\n",
            "Patient 14: Probability = 0.0000\n",
            "Patient 15: Probability = 0.0000\n",
            "Patient 16: Probability = 0.0000\n",
            "Patient 17: Probability = 0.0000\n",
            "Patient 18: Probability = 0.0000\n",
            "Patient 19: Probability = 0.0000\n",
            "Patient 20: Probability = 0.0000\n",
            "Patient 21: Probability = 0.0000\n",
            "Patient 22: Probability = 0.0000\n",
            "Patient 23: Probability = 0.0000\n",
            "Patient 24: Probability = 0.0000\n",
            "Patient 25: Probability = 0.0000\n",
            "Patient 26: Probability = 0.0000\n",
            "Patient 27: Probability = 0.0000\n",
            "Patient 28: Probability = 0.0000\n",
            "Patient 29: Probability = 0.0000\n",
            "Patient 30: Probability = 0.0000\n",
            "Patient 31: Probability = 0.0000\n",
            "Patient 32: Probability = 0.0000\n",
            "Patient 33: Probability = 0.0000\n",
            "Patient 34: Probability = 0.0000\n",
            "Patient 35: Probability = 0.0000\n",
            "Patient 36: Probability = 0.0000\n",
            "Patient 37: Probability = 0.0000\n",
            "Patient 38: Probability = 0.0000\n",
            "Patient 39: Probability = 0.0000\n",
            "Patient 40: Probability = 0.0000\n",
            "Patient 41: Probability = 0.0000\n",
            "Patient 42: Probability = 0.0000\n",
            "Patient 43: Probability = 0.0000\n",
            "Patient 44: Probability = 0.0000\n",
            "Patient 45: Probability = 0.0000\n",
            "Patient 46: Probability = 0.0000\n",
            "Patient 47: Probability = 0.0000\n",
            "Patient 48: Probability = 0.0000\n",
            "Patient 49: Probability = 0.0000\n",
            "Patient 50: Probability = 0.0000\n",
            "Patient 51: Probability = 0.0000\n",
            "Patient 52: Probability = 0.0000\n",
            "Patient 53: Probability = 0.0000\n",
            "Patient 54: Probability = 0.0000\n",
            "Patient 55: Probability = 0.0000\n",
            "Patient 56: Probability = 0.0000\n",
            "Patient 57: Probability = 0.0000\n",
            "Patient 58: Probability = 0.0000\n",
            "Patient 59: Probability = 0.0000\n",
            "Patient 60: Probability = 0.0000\n",
            "Patient 61: Probability = 0.0000\n",
            "Patient 62: Probability = 0.0000\n",
            "Patient 63: Probability = 0.0000\n",
            "Patient 64: Probability = 0.0000\n",
            "Patient 65: Probability = 0.0000\n",
            "Patient 66: Probability = 0.0000\n",
            "Patient 67: Probability = 0.0000\n",
            "Patient 68: Probability = 0.0000\n",
            "Patient 69: Probability = 0.0000\n",
            "Patient 70: Probability = 0.0000\n",
            "Patient 71: Probability = 0.0000\n",
            "Patient 72: Probability = 0.0000\n",
            "Patient 73: Probability = 0.0000\n",
            "Patient 74: Probability = 0.0000\n",
            "Patient 75: Probability = 0.0000\n",
            "Patient 76: Probability = 0.0000\n",
            "Patient 77: Probability = 0.0000\n",
            "Patient 78: Probability = 0.0000\n",
            "Patient 79: Probability = 0.0000\n",
            "Patient 80: Probability = 0.0000\n",
            "Patient 81: Probability = 0.0000\n",
            "Patient 82: Probability = 0.0000\n",
            "Patient 83: Probability = 0.0000\n",
            "Patient 84: Probability = 0.0000\n",
            "Patient 85: Probability = 0.0000\n",
            "Patient 86: Probability = 0.0000\n",
            "Patient 87: Probability = 0.0000\n",
            "Patient 88: Probability = 0.0000\n",
            "Patient 89: Probability = 0.0000\n",
            "Patient 90: Probability = 0.0000\n",
            "Patient 91: Probability = 0.0000\n",
            "Patient 92: Probability = 0.0000\n",
            "Patient 93: Probability = 0.0000\n",
            "Patient 94: Probability = 0.0000\n",
            "Patient 95: Probability = 0.0000\n",
            "Patient 96: Probability = 0.0000\n",
            "Patient 97: Probability = 0.0000\n",
            "Patient 98: Probability = 0.0000\n",
            "Patient 99: Probability = 0.0000\n",
            "Patient 100: Probability = 0.0000\n",
            "Patient 101: Probability = 0.0000\n",
            "Patient 102: Probability = 0.0000\n",
            "Patient 103: Probability = 0.0000\n",
            "Patient 104: Probability = 0.0000\n",
            "Patient 105: Probability = 0.0000\n",
            "Patient 106: Probability = 0.0000\n",
            "Patient 107: Probability = 0.0000\n",
            "Patient 108: Probability = 0.0000\n",
            "Patient 109: Probability = 0.0000\n",
            "Patient 110: Probability = 0.0000\n",
            "Patient 111: Probability = 0.0000\n",
            "Patient 112: Probability = 0.0000\n",
            "Patient 113: Probability = 0.0000\n",
            "Patient 114: Probability = 0.0000\n",
            "Patient 115: Probability = 0.0000\n",
            "Patient 116: Probability = 0.0000\n",
            "Patient 117: Probability = 0.0000\n",
            "Patient 118: Probability = 0.0000\n",
            "Patient 119: Probability = 0.0000\n",
            "Patient 120: Probability = 0.0000\n",
            "Patient 121: Probability = 0.0000\n",
            "Patient 122: Probability = 0.0000\n",
            "Patient 123: Probability = 0.0000\n",
            "Patient 124: Probability = 0.0000\n",
            "Patient 125: Probability = 0.0000\n",
            "Patient 126: Probability = 0.0000\n",
            "Patient 127: Probability = 0.0000\n",
            "Patient 128: Probability = 0.0000\n",
            "Patient 129: Probability = 0.0000\n",
            "Patient 130: Probability = 0.0000\n",
            "Patient 131: Probability = 0.0000\n",
            "Patient 132: Probability = 0.0000\n",
            "Patient 133: Probability = 0.0000\n",
            "Patient 134: Probability = 0.0000\n",
            "Patient 135: Probability = 0.0000\n",
            "Patient 136: Probability = 0.0000\n",
            "Patient 137: Probability = 0.0000\n",
            "Patient 138: Probability = 0.0000\n",
            "Patient 139: Probability = 0.0000\n",
            "Patient 140: Probability = 0.0000\n",
            "Patient 141: Probability = 0.0000\n",
            "Patient 142: Probability = 0.0000\n",
            "Patient 143: Probability = 0.0000\n",
            "Patient 144: Probability = 0.0000\n",
            "Patient 145: Probability = 0.0000\n",
            "Patient 146: Probability = 0.0000\n",
            "Patient 147: Probability = 0.0000\n",
            "Patient 148: Probability = 0.0000\n",
            "Patient 149: Probability = 0.0000\n",
            "Patient 150: Probability = 0.0000\n",
            "Patient 151: Probability = 0.0000\n",
            "Patient 152: Probability = 0.0000\n",
            "Patient 153: Probability = 0.0000\n",
            "Patient 154: Probability = 0.0000\n",
            "Patient 155: Probability = 0.0000\n",
            "Patient 156: Probability = 0.0000\n",
            "Patient 157: Probability = 0.0000\n",
            "Patient 158: Probability = 0.0000\n",
            "Patient 159: Probability = 0.0000\n",
            "Patient 160: Probability = 0.0000\n",
            "Patient 161: Probability = 0.0000\n",
            "Patient 162: Probability = 0.0000\n",
            "Patient 163: Probability = 0.0000\n",
            "Patient 164: Probability = 0.0000\n",
            "Patient 165: Probability = 0.0000\n",
            "Patient 166: Probability = 0.0000\n",
            "Patient 167: Probability = 0.0000\n",
            "Patient 168: Probability = 0.0000\n",
            "Patient 169: Probability = 0.0000\n",
            "Patient 170: Probability = 0.0000\n",
            "Patient 171: Probability = 0.0000\n",
            "Patient 172: Probability = 0.0000\n",
            "Patient 173: Probability = 0.0000\n",
            "Patient 174: Probability = 0.0000\n",
            "Patient 175: Probability = 0.0000\n",
            "Patient 176: Probability = 0.0000\n",
            "Patient 177: Probability = 0.0000\n",
            "Patient 178: Probability = 0.0000\n",
            "Patient 179: Probability = 0.0000\n",
            "Patient 180: Probability = 0.0000\n",
            "Patient 181: Probability = 0.0000\n",
            "Patient 182: Probability = 0.0000\n",
            "Patient 183: Probability = 0.0000\n",
            "Patient 184: Probability = 0.0000\n",
            "Patient 185: Probability = 0.0000\n",
            "Patient 186: Probability = 0.0000\n",
            "Patient 187: Probability = 0.0000\n",
            "Patient 188: Probability = 0.0000\n",
            "Patient 189: Probability = 0.0000\n",
            "Patient 190: Probability = 0.0000\n",
            "Patient 191: Probability = 0.0000\n",
            "Patient 192: Probability = 0.0000\n",
            "Patient 193: Probability = 0.0000\n",
            "Patient 194: Probability = 0.0000\n",
            "Patient 195: Probability = 0.0000\n",
            "Patient 196: Probability = 0.0000\n",
            "Patient 197: Probability = 0.0000\n",
            "Patient 198: Probability = 0.0000\n",
            "Patient 199: Probability = 0.0000\n",
            "Patient 200: Probability = 0.0000\n",
            "Patient 201: Probability = 0.0000\n",
            "Patient 202: Probability = 0.0000\n",
            "Patient 203: Probability = 0.0000\n",
            "Patient 204: Probability = 0.0000\n",
            "Patient 205: Probability = 0.0000\n",
            "Patient 206: Probability = 0.0000\n",
            "Patient 207: Probability = 0.0000\n",
            "Patient 208: Probability = 0.0000\n",
            "Patient 209: Probability = 0.0000\n",
            "Patient 210: Probability = 0.0000\n",
            "Patient 211: Probability = 0.0000\n",
            "Patient 212: Probability = 0.0000\n",
            "Patient 213: Probability = 0.0000\n",
            "Patient 214: Probability = 0.0000\n",
            "Patient 215: Probability = 0.0000\n",
            "Patient 216: Probability = 0.0000\n",
            "Patient 217: Probability = 0.0000\n",
            "Patient 218: Probability = 0.0000\n",
            "Patient 219: Probability = 0.0000\n",
            "Patient 220: Probability = 0.0000\n",
            "Patient 221: Probability = 0.0000\n",
            "Patient 222: Probability = 0.0000\n",
            "Patient 223: Probability = 0.0000\n",
            "Patient 224: Probability = 0.0000\n",
            "Patient 225: Probability = 0.0000\n",
            "Patient 226: Probability = 0.0000\n",
            "Patient 227: Probability = 0.0000\n",
            "Patient 228: Probability = 0.0000\n",
            "Patient 229: Probability = 0.0000\n",
            "Patient 230: Probability = 0.0000\n",
            "Patient 231: Probability = 0.0000\n",
            "Patient 232: Probability = 0.0000\n",
            "Patient 233: Probability = 0.0000\n",
            "Patient 234: Probability = 0.0000\n",
            "Patient 235: Probability = 0.0000\n",
            "Patient 236: Probability = 0.0000\n",
            "Patient 237: Probability = 0.0000\n",
            "Patient 238: Probability = 0.0000\n",
            "Patient 239: Probability = 0.0000\n",
            "Patient 240: Probability = 0.0000\n",
            "Patient 241: Probability = 0.0000\n",
            "Patient 242: Probability = 0.0000\n",
            "Patient 243: Probability = 0.0000\n",
            "Patient 244: Probability = 0.0000\n",
            "Patient 245: Probability = 0.0000\n",
            "Patient 246: Probability = 0.0000\n",
            "Patient 247: Probability = 0.0000\n",
            "Patient 248: Probability = 0.0000\n",
            "Patient 249: Probability = 0.0000\n",
            "Patient 250: Probability = 0.0000\n",
            "Patient 251: Probability = 0.0000\n",
            "Patient 252: Probability = 0.0000\n",
            "Patient 253: Probability = 0.0000\n",
            "Patient 254: Probability = 0.0000\n",
            "Patient 255: Probability = 0.0000\n",
            "Patient 256: Probability = 0.0000\n",
            "Patient 257: Probability = 0.0000\n",
            "Patient 258: Probability = 0.0000\n",
            "Patient 259: Probability = 0.0000\n",
            "Patient 260: Probability = 0.0000\n",
            "Patient 261: Probability = 0.0000\n",
            "Patient 262: Probability = 0.0000\n",
            "Patient 263: Probability = 0.0000\n",
            "Patient 264: Probability = 0.0000\n",
            "Patient 265: Probability = 0.0000\n",
            "Patient 266: Probability = 0.0000\n",
            "Patient 267: Probability = 0.0000\n",
            "Patient 268: Probability = 0.0000\n",
            "Patient 269: Probability = 0.0000\n",
            "Patient 270: Probability = 0.0000\n",
            "Patient 271: Probability = 0.0000\n",
            "Patient 272: Probability = 0.0000\n",
            "Patient 273: Probability = 0.0000\n",
            "Patient 274: Probability = 0.0000\n",
            "Patient 275: Probability = 0.0000\n",
            "Patient 276: Probability = 0.0000\n",
            "Patient 277: Probability = 0.0000\n",
            "Patient 278: Probability = 0.0000\n",
            "Patient 279: Probability = 0.0000\n",
            "Patient 280: Probability = 0.0000\n",
            "Patient 281: Probability = 0.0000\n",
            "Patient 282: Probability = 0.0000\n",
            "Patient 283: Probability = 0.0000\n",
            "Patient 284: Probability = 0.0000\n",
            "Patient 285: Probability = 0.0000\n",
            "Patient 286: Probability = 0.0000\n",
            "Patient 287: Probability = 0.0000\n",
            "Patient 288: Probability = 0.0000\n",
            "Patient 289: Probability = 0.0000\n",
            "Patient 290: Probability = 0.0000\n",
            "Patient 291: Probability = 0.0000\n",
            "Patient 292: Probability = 0.0000\n",
            "Patient 293: Probability = 0.0000\n",
            "Patient 294: Probability = 0.0000\n",
            "Patient 295: Probability = 0.0000\n",
            "Patient 296: Probability = 0.0000\n",
            "Patient 297: Probability = 0.0000\n",
            "Patient 298: Probability = 0.0000\n",
            "Patient 299: Probability = 0.0000\n",
            "Patient 300: Probability = 0.0000\n",
            "Patient 301: Probability = 0.0000\n",
            "Patient 302: Probability = 0.0000\n",
            "Patient 303: Probability = 0.0000\n",
            "Patient 304: Probability = 0.0000\n",
            "Patient 305: Probability = 0.0000\n",
            "Patient 306: Probability = 0.0000\n",
            "Patient 307: Probability = 0.0000\n",
            "Patient 308: Probability = 0.0000\n",
            "Patient 309: Probability = 0.0000\n",
            "Patient 310: Probability = 0.0000\n",
            "Patient 311: Probability = 0.0000\n",
            "Patient 312: Probability = 0.0000\n",
            "Patient 313: Probability = 0.0000\n",
            "Patient 314: Probability = 0.0000\n",
            "Patient 315: Probability = 0.0000\n",
            "Patient 316: Probability = 0.0000\n",
            "Patient 317: Probability = 0.0000\n",
            "Patient 318: Probability = 0.0000\n",
            "Patient 319: Probability = 0.0000\n",
            "Patient 320: Probability = 0.0000\n",
            "Patient 321: Probability = 0.0000\n",
            "Patient 322: Probability = 0.0000\n",
            "Patient 323: Probability = 0.0000\n",
            "Patient 324: Probability = 0.0000\n",
            "Patient 325: Probability = 0.0000\n",
            "Patient 326: Probability = 0.0000\n",
            "Patient 327: Probability = 0.0000\n",
            "Patient 328: Probability = 0.0000\n",
            "Patient 329: Probability = 0.0000\n",
            "Patient 330: Probability = 0.0000\n",
            "Patient 331: Probability = 0.0000\n",
            "Patient 332: Probability = 0.0000\n",
            "Patient 333: Probability = 0.0000\n",
            "Patient 334: Probability = 0.0000\n",
            "Patient 335: Probability = 0.0000\n",
            "Patient 336: Probability = 0.0000\n",
            "Patient 337: Probability = 0.0000\n",
            "Patient 338: Probability = 0.0000\n",
            "Patient 339: Probability = 0.0000\n",
            "Patient 340: Probability = 0.0000\n",
            "Patient 341: Probability = 0.0000\n",
            "Patient 342: Probability = 0.0000\n",
            "Patient 343: Probability = 0.0000\n",
            "Patient 344: Probability = 0.0000\n",
            "Patient 345: Probability = 0.0000\n",
            "Patient 346: Probability = 0.0000\n",
            "Patient 347: Probability = 0.0000\n",
            "Patient 348: Probability = 0.0000\n",
            "Patient 349: Probability = 0.0000\n",
            "Patient 350: Probability = 0.0000\n",
            "Patient 351: Probability = 0.0000\n",
            "Patient 352: Probability = 0.0000\n",
            "Patient 353: Probability = 0.0000\n",
            "Patient 354: Probability = 0.0000\n",
            "Patient 355: Probability = 0.0000\n",
            "Patient 356: Probability = 0.0000\n",
            "Patient 357: Probability = 0.0000\n",
            "Patient 358: Probability = 0.0000\n",
            "Patient 359: Probability = 0.0000\n",
            "Patient 360: Probability = 0.0000\n",
            "Patient 361: Probability = 0.0000\n",
            "Patient 362: Probability = 0.0000\n",
            "Patient 363: Probability = 0.0000\n",
            "Patient 364: Probability = 0.0000\n",
            "Patient 365: Probability = 0.0000\n",
            "Patient 366: Probability = 0.0000\n",
            "Patient 367: Probability = 0.0000\n",
            "Patient 368: Probability = 0.0000\n",
            "Patient 369: Probability = 0.0000\n",
            "Patient 370: Probability = 0.0000\n",
            "Patient 371: Probability = 0.0000\n",
            "Patient 372: Probability = 0.0000\n",
            "Patient 373: Probability = 0.0000\n",
            "Patient 374: Probability = 0.0000\n",
            "Patient 375: Probability = 0.0000\n",
            "Patient 376: Probability = 0.0000\n",
            "Patient 377: Probability = 0.0000\n",
            "Patient 378: Probability = 0.0000\n",
            "Patient 379: Probability = 0.0000\n",
            "Patient 380: Probability = 0.0000\n",
            "Patient 381: Probability = 0.0000\n",
            "Patient 382: Probability = 0.0000\n",
            "Patient 383: Probability = 0.0000\n",
            "Patient 384: Probability = 0.0000\n",
            "Patient 385: Probability = 0.0000\n",
            "Patient 386: Probability = 0.0000\n",
            "Patient 387: Probability = 0.0000\n",
            "Patient 388: Probability = 0.0000\n",
            "Patient 389: Probability = 0.0000\n",
            "Patient 390: Probability = 0.0000\n",
            "Patient 391: Probability = 0.0000\n",
            "Patient 392: Probability = 0.0000\n",
            "Patient 393: Probability = 0.0000\n",
            "Patient 394: Probability = 0.0000\n",
            "Patient 395: Probability = 0.0000\n",
            "Patient 396: Probability = 0.0000\n",
            "Patient 397: Probability = 0.0000\n",
            "Patient 398: Probability = 0.0000\n",
            "Patient 399: Probability = 0.0000\n",
            "Patient 400: Probability = 0.0000\n",
            "Patient 401: Probability = 0.0000\n",
            "Patient 402: Probability = 0.0000\n",
            "Patient 403: Probability = 0.0000\n",
            "Patient 404: Probability = 0.0000\n",
            "Patient 405: Probability = 0.0000\n",
            "Patient 406: Probability = 0.0000\n",
            "Patient 407: Probability = 0.0000\n",
            "Patient 408: Probability = 0.0000\n",
            "Patient 409: Probability = 0.0000\n",
            "Patient 410: Probability = 0.0000\n",
            "Patient 411: Probability = 0.0000\n",
            "Patient 412: Probability = 0.0000\n",
            "Patient 413: Probability = 0.0000\n",
            "Patient 414: Probability = 0.0000\n",
            "Patient 415: Probability = 0.0000\n",
            "Patient 416: Probability = 0.0000\n",
            "Patient 417: Probability = 0.0000\n",
            "Patient 418: Probability = 0.0000\n",
            "Patient 419: Probability = 0.0000\n",
            "Patient 420: Probability = 0.0000\n",
            "Patient 421: Probability = 0.0000\n",
            "Patient 422: Probability = 0.0000\n",
            "Patient 423: Probability = 0.0000\n",
            "Patient 424: Probability = 0.0000\n",
            "Patient 425: Probability = 0.0000\n",
            "Patient 426: Probability = 0.0000\n",
            "Patient 427: Probability = 0.0000\n",
            "Patient 428: Probability = 0.0000\n",
            "Patient 429: Probability = 0.0000\n",
            "Patient 430: Probability = 0.0000\n",
            "Patient 431: Probability = 0.0000\n",
            "Patient 432: Probability = 0.0000\n",
            "Patient 433: Probability = 0.0000\n",
            "Patient 434: Probability = 0.0000\n",
            "Patient 435: Probability = 0.0000\n",
            "Patient 436: Probability = 0.0000\n",
            "Patient 437: Probability = 0.0000\n",
            "Patient 438: Probability = 0.0000\n",
            "Patient 439: Probability = 0.0000\n",
            "Patient 440: Probability = 0.0000\n",
            "Patient 441: Probability = 0.0000\n",
            "Patient 442: Probability = 0.0000\n",
            "Patient 443: Probability = 0.0000\n",
            "Patient 444: Probability = 0.0000\n",
            "Patient 445: Probability = 0.0000\n",
            "Patient 446: Probability = 0.0000\n",
            "Patient 447: Probability = 0.0000\n",
            "Patient 448: Probability = 0.0000\n",
            "Patient 449: Probability = 0.0000\n",
            "Patient 450: Probability = 0.0000\n",
            "Patient 451: Probability = 0.0000\n",
            "Patient 452: Probability = 0.0000\n",
            "Patient 453: Probability = 0.0000\n",
            "Patient 454: Probability = 0.0000\n",
            "Patient 455: Probability = 0.0000\n",
            "Patient 456: Probability = 0.0000\n",
            "Patient 457: Probability = 0.0000\n",
            "Patient 458: Probability = 0.0000\n",
            "Patient 459: Probability = 0.0000\n",
            "Patient 460: Probability = 0.0000\n",
            "Patient 461: Probability = 0.0000\n",
            "Patient 462: Probability = 0.0000\n",
            "Patient 463: Probability = 0.0000\n",
            "Patient 464: Probability = 0.0000\n",
            "Patient 465: Probability = 0.0000\n",
            "Patient 466: Probability = 0.0000\n",
            "Patient 467: Probability = 0.0000\n",
            "Patient 468: Probability = 0.0000\n",
            "Patient 469: Probability = 0.0000\n",
            "Patient 470: Probability = 0.0000\n",
            "Patient 471: Probability = 0.0000\n",
            "Patient 472: Probability = 0.0000\n",
            "Patient 473: Probability = 0.0000\n",
            "Patient 474: Probability = 0.0000\n",
            "Patient 475: Probability = 0.0000\n",
            "Patient 476: Probability = 0.0000\n",
            "Patient 477: Probability = 0.0000\n",
            "Patient 478: Probability = 0.0000\n",
            "Patient 479: Probability = 0.0000\n",
            "Patient 480: Probability = 0.0000\n",
            "Patient 481: Probability = 0.0000\n",
            "Patient 482: Probability = 0.0000\n",
            "Patient 483: Probability = 0.0000\n",
            "Patient 484: Probability = 0.0000\n",
            "Patient 485: Probability = 0.0000\n",
            "Patient 486: Probability = 0.0000\n",
            "Patient 487: Probability = 0.0000\n",
            "Patient 488: Probability = 0.0000\n",
            "Patient 489: Probability = 0.0000\n",
            "Patient 490: Probability = 0.0000\n",
            "Patient 491: Probability = 0.0000\n",
            "Patient 492: Probability = 0.0000\n",
            "Patient 493: Probability = 0.0000\n",
            "Patient 494: Probability = 0.0000\n",
            "Patient 495: Probability = 0.0000\n",
            "Patient 496: Probability = 0.0000\n",
            "Patient 497: Probability = 0.0000\n",
            "Patient 498: Probability = 0.0000\n",
            "Patient 499: Probability = 0.0000\n",
            "Patient 500: Probability = 0.0000\n",
            "Patient 501: Probability = 0.0000\n",
            "Patient 502: Probability = 0.0000\n",
            "Patient 503: Probability = 0.0000\n",
            "Patient 504: Probability = 0.0000\n",
            "Patient 505: Probability = 0.0000\n",
            "Patient 506: Probability = 0.0000\n",
            "Patient 507: Probability = 0.0000\n",
            "Patient 508: Probability = 0.0000\n",
            "Patient 509: Probability = 0.0000\n",
            "Patient 510: Probability = 0.0000\n",
            "Patient 511: Probability = 0.0000\n",
            "Patient 512: Probability = 0.0000\n",
            "Patient 513: Probability = 0.0000\n",
            "Patient 514: Probability = 0.0000\n",
            "Patient 515: Probability = 0.0000\n",
            "Patient 516: Probability = 0.0000\n",
            "Patient 517: Probability = 0.0000\n",
            "Patient 518: Probability = 0.0000\n",
            "Patient 519: Probability = 0.0000\n",
            "Patient 520: Probability = 0.0000\n",
            "Patient 521: Probability = 0.0000\n",
            "Patient 522: Probability = 0.0000\n",
            "Patient 523: Probability = 0.0000\n",
            "Patient 524: Probability = 0.0000\n",
            "Patient 525: Probability = 0.0000\n",
            "Patient 526: Probability = 0.0000\n",
            "Patient 527: Probability = 0.0000\n",
            "Patient 528: Probability = 0.0000\n",
            "Patient 529: Probability = 0.0000\n",
            "Patient 530: Probability = 0.0000\n",
            "Patient 531: Probability = 0.0000\n",
            "Patient 532: Probability = 0.0000\n",
            "Patient 533: Probability = 0.0000\n",
            "Patient 534: Probability = 0.0000\n",
            "Patient 535: Probability = 0.0000\n",
            "Patient 536: Probability = 0.0000\n",
            "Patient 537: Probability = 0.0000\n",
            "Patient 538: Probability = 0.0000\n",
            "Patient 539: Probability = 0.0000\n",
            "Patient 540: Probability = 0.0000\n",
            "Patient 541: Probability = 0.0000\n",
            "Patient 542: Probability = 0.0000\n",
            "Patient 543: Probability = 0.0000\n",
            "Patient 544: Probability = 0.0000\n",
            "Patient 545: Probability = 0.0000\n",
            "Patient 546: Probability = 0.0000\n",
            "Patient 547: Probability = 0.0000\n",
            "Patient 548: Probability = 0.0000\n",
            "Patient 549: Probability = 0.0000\n",
            "Patient 550: Probability = 0.0000\n",
            "Patient 551: Probability = 0.0000\n",
            "Patient 552: Probability = 0.0000\n",
            "Patient 553: Probability = 0.0000\n",
            "Patient 554: Probability = 0.0000\n",
            "Patient 555: Probability = 0.0000\n",
            "Patient 556: Probability = 0.0000\n",
            "Patient 557: Probability = 0.0000\n",
            "Patient 558: Probability = 0.0000\n",
            "Patient 559: Probability = 0.0000\n",
            "Patient 560: Probability = 0.0000\n",
            "Patient 561: Probability = 0.0000\n",
            "Patient 562: Probability = 0.0000\n",
            "Patient 563: Probability = 0.0000\n",
            "Patient 564: Probability = 0.0000\n",
            "Patient 565: Probability = 0.0000\n",
            "Patient 566: Probability = 0.0000\n",
            "Patient 567: Probability = 0.0000\n",
            "Patient 568: Probability = 0.0000\n",
            "\n",
            "Total high-risk patients found: 569 out of 569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**\n",
        "\n",
        "Here we are just multipying random weight values to the input datas we have it is like guessing in the exam hall without knowing answers at all.So it is nonconsistent at all."
      ],
      "metadata": {
        "id": "IphEhPGiVu10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution**\n",
        "\n",
        "* So we have to show teach it the correct answer i.e train the model\n",
        "* So steps of that is:\n",
        "  * Show the output (Y)\n",
        "  * Compare the current probability prediction with the Y\n",
        "  * Introduce error so that we know how much it differ\n",
        "  * Try to minimize that error so that the accuracy is increased and this prediction is reliable and consistent\n"
      ],
      "metadata": {
        "id": "MbYK5mHKWK1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression cost function"
      ],
      "metadata": {
        "id": "OT-jFx8vl6km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is the error that or the variation that is seen between predcted value and actual value .\n",
        "\n",
        "The goal of the model is to change the weights and biases to reduce the cost function."
      ],
      "metadata": {
        "id": "F-aBzlGyXtAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$J = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(a^{(i)}) + (1-y^{(i)}) \\log(1-a^{(i)})]$$"
      ],
      "metadata": {
        "id": "m1E0b-VIYXF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(y_hat,Y,m):\n",
        "  epsilon = 1e-15\n",
        "  total_cost = 0\n",
        "  for i in range(m):\n",
        "    a_i = y_hat[0, i]#prediction\n",
        "    y_i = Y[0, i]#label\n",
        "\n",
        "    #Since log(0) is undefined (-inf), we clip a_i to be slightly above 0 and below 1\n",
        "    a_i = np.clip(a_i, epsilon, 1 - epsilon)\n",
        "\n",
        "    loss_i = -(y_i * np.log(a_i) + (1 - y_i) * np.log(1 - a_i))\n",
        "\n",
        "    # Summation\n",
        "    total_cost += loss_i\n",
        "\n",
        "  # Average cost\n",
        "  J = total_cost / m\n",
        "  return J"
      ],
      "metadata": {
        "id": "FFGgUq1Rl9MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis:**\n",
        "\n",
        "As we see the Cost is very high so now we have to calcule the difference and minimize the cost by changing the"
      ],
      "metadata": {
        "id": "ZqvZTL8BcDQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent"
      ],
      "metadata": {
        "id": "cnB2hT5_l9w1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is the technique to minimize the cost by taking small steps towards towards the minimum by finding the parital derivative."
      ],
      "metadata": {
        "id": "dYxJk8O0enfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partial derivative tells us the slope. Moving against the slope (subtracting the gradient) is what leads us \"downhill\" to the minimum cost."
      ],
      "metadata": {
        "id": "SdfEegionISU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "gradient descent is described as:\n",
        "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
        "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w}  \\; \\newline\n",
        " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
        "\\end{align*}$$\n",
        "where, parameters $w$, $b$ are updated simultaneously.  \n",
        "The gradient is defined as:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\\\\n",
        "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Here *simultaniously* means that you calculate the partial derivatives for all the parameters before updating any of the parameters."
      ],
      "metadata": {
        "id": "Oo77KEAEhqUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So in code\n",
        "$$w = w - \\alpha \\cdot dw$$$$b = b - \\alpha \\cdot db$$\n",
        "\n",
        "$\\alpha$ (Alpha): Learning rate,controls how big the step is.\n",
        "\n",
        "$dw$ and $db$:gradients;partial derivative of cost function with respect to w and b.\n"
      ],
      "metadata": {
        "id": "ZDkY0w6nezXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Gradient Descent Loop:**\n",
        "* Forward Propagation:Calcualte Y_hat and the Cost\n",
        "* Backpropagation:Calculate dw and db\n",
        "* Change w and b slightly\n",
        "* Repeat"
      ],
      "metadata": {
        "id": "gRuob1yuf3Ud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$dw_j = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)} - y^{(i)}) \\cdot x_j^{(i)}$$\n",
        "\n",
        "$$db = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)} - y^{(i)})$$"
      ],
      "metadata": {
        "id": "JhbOl6u6hHXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 2000\n",
        "learning_rate = 0.01\n",
        "costs = []"
      ],
      "metadata": {
        "id": "Bwy7rKWWgnQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def back_prop(X, A, Y, nx, m):\n",
        "    dw = np.zeros((nx, 1))\n",
        "    db = 0.0\n",
        "    for i in range(m):\n",
        "        dz_i = A[0, i] - Y[0, i]\n",
        "        for j in range(nx):\n",
        "            dw[j, 0] += X[j, i] * dz_i\n",
        "        db += dz_i\n",
        "    return dw / m, db / m"
      ],
      "metadata": {
        "id": "SPD-3tO7og5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X,Y,w_in,b_in,iterations,learning_rate):\n",
        "  w= copy.deepcopy(w_in)\n",
        "  b=b_in\n",
        "  nx,m=X.shape\n",
        "  cost_history = []\n",
        "\n",
        "  for epoch in range(iterations):\n",
        "    total_cost = 0.0\n",
        "    # 1. Forward Propagation\n",
        "    y_hat = forward_prop(X, w, b, m, nx)\n",
        "\n",
        "     # 2. Cost Finding\n",
        "    cost = compute_cost(y_hat, Y, m)\n",
        "    cost_history.append(cost)\n",
        "\n",
        "    # 3. Backward Propagation\n",
        "    dw, db = back_prop(X, y_hat, Y, nx, m)\n",
        "\n",
        "    # 4. UPDATE PARAMETERS(Gradient descent part)\n",
        "    for j in range(nx):\n",
        "        w[j, 0] = w[j, 0] - learning_rate * dw[j, 0]\n",
        "    b = b - learning_rate * db\n",
        "\n",
        "    #printing the cost in each 100 epoch intervatal\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Iteration {epoch}: Cost {cost:.6f}\")\n",
        "  return w,b,cost_history"
      ],
      "metadata": {
        "id": "ZfadO70bgjV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights,bias,J_history=model(X,Y,w,b,iterations,learning_rate)\n",
        "print(\"-\" * 30)\n",
        "print(f\"Final Weights:\\n{weights}\")\n",
        "print(f\"Final Bias: {bias:.6f}\")\n",
        "\n",
        "# 4. Visualization (The most effective way to show it works)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(J_history)\n",
        "plt.title(\"Cost Reduction over Time\")\n",
        "plt.xlabel(\"Iterations (per hundred)\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TWH9NkZUotYh",
        "outputId": "5e0b339c-4188-4b2b-f0de-0e213a925153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost 7.462311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2487351055.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100: Cost 21.622255\n",
            "Iteration 200: Cost 4.410937\n",
            "Iteration 300: Cost 5.326605\n",
            "Iteration 400: Cost 3.456971\n",
            "Iteration 500: Cost 3.548517\n",
            "Iteration 600: Cost 3.354920\n",
            "Iteration 700: Cost 3.563500\n",
            "Iteration 800: Cost 3.234741\n",
            "Iteration 900: Cost 3.517543\n",
            "Iteration 1000: Cost 3.655983\n",
            "Iteration 1100: Cost 3.435751\n",
            "Iteration 1200: Cost 3.421088\n",
            "Iteration 1300: Cost 3.448873\n",
            "Iteration 1400: Cost 3.366683\n",
            "Iteration 1500: Cost 2.814467\n",
            "Iteration 1600: Cost 2.685296\n",
            "Iteration 1700: Cost 2.619100\n",
            "Iteration 1800: Cost 2.556852\n",
            "Iteration 1900: Cost 2.604678\n",
            "------------------------------\n",
            "Final Weights:\n",
            "[[ 3.39160640e+00]\n",
            " [ 2.65687941e+00]\n",
            " [ 1.87869338e+01]\n",
            " [ 6.28012671e+00]\n",
            " [ 3.65297140e-02]\n",
            " [-4.99836686e-02]\n",
            " [-1.12770509e-01]\n",
            " [-4.34529532e-02]\n",
            " [ 5.41573652e-02]\n",
            " [ 2.12134456e-02]\n",
            " [ 9.14702575e-03]\n",
            " [ 1.57677881e-01]\n",
            " [-3.13911398e-01]\n",
            " [-9.87496884e+00]\n",
            " [-2.59724682e-03]\n",
            " [-3.56684135e-03]\n",
            " [-6.11091486e-03]\n",
            " [ 9.57002859e-03]\n",
            " [-8.97854885e-03]\n",
            " [ 6.49848506e-03]\n",
            " [ 3.64931736e+00]\n",
            " [ 2.87855586e+00]\n",
            " [ 1.83136000e+01]\n",
            " [-7.09189540e+00]\n",
            " [ 3.11884398e-02]\n",
            " [-1.60959919e-01]\n",
            " [-2.59805125e-01]\n",
            " [-3.71610342e-02]\n",
            " [ 3.50112946e-02]\n",
            " [ 9.31576410e-03]]\n",
            "Final Bias: 0.447845\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**:\n",
        "\n",
        "For running above code we need to do backward propagation i.e we need to do derivative and find db and dw"
      ],
      "metadata": {
        "id": "wocWU012nzMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derivatives"
      ],
      "metadata": {
        "id": "yeWSZV6cj934"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For various functions and do backward propagation derivative is necessary."
      ],
      "metadata": {
        "id": "RdQbdTaJSxHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def back_prop(X, y_hat, Y, nx, m):\n",
        "    # Initialize gradients as zero\n",
        "    dw = [[0.0] for _ in range(nx)]\n",
        "    db = 0.0\n",
        "\n",
        "    for i in range(m):  # For every training example\n",
        "        # Local derivative: dLoss/dz = (y_hat - y)\n",
        "        dz = y_hat[i] - Y[0, i]\n",
        "\n",
        "        for j in range(nx):  # For every feature\n",
        "            # Chain Rule: dL/dw_j = dz * dz/dw_j = dz * x_j\n",
        "            dw[j][0] += dz * X[j, i]\n",
        "\n",
        "        # Chain Rule: dL/db = dz * dz/db = dz * 1\n",
        "        db += dz\n",
        "\n",
        "    # Average the gradients over all examples\n",
        "    for j in range(nx):\n",
        "        dw[j][0] /= m\n",
        "    db /= m\n",
        "\n",
        "    return dw, db"
      ],
      "metadata": {
        "id": "tAe-Bjj_j_lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Gradient Descent"
      ],
      "metadata": {
        "id": "v4aK6pXAXcRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Recall the gradient descent algorithm utilizes the gradient calculation:\n",
        "$$\\begin{align*}\n",
        "&\\text{repeat until convergence:} \\; \\lbrace \\\\\n",
        "&  \\; \\; \\;w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  \\; & \\text{for j := 0..n-1} \\\\\n",
        "&  \\; \\; \\;  \\; \\;b = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\\\\n",
        "&\\rbrace\n",
        "\\end{align*}$$\n",
        "\n",
        "Where each iteration performs simultaneous updates on $w_j$ for all $j$, where\n",
        "$$\\begin{align*}\n",
        "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)}  \\\\\n",
        "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})\n",
        "\\end{align*}$$\n",
        "\n",
        "* m is the number of training examples in the data set      \n",
        "* $f_{\\mathbf{w},b}(x^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target\n",
        "    \n"
      ],
      "metadata": {
        "id": "J3aB2owOiZkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression Model\n",
        "The prediction is calculated as:\n",
        "\n",
        "\n",
        "The output is passed through the sigmoid function:\n",
        "$$f_{\\mathbf{w},b}(x) = g(z)$$\n",
        "\n",
        "Where $g(z)$ is defined as:\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}$$"
      ],
      "metadata": {
        "id": "kI7_2gdIjb0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_logistic(X, y, w, b):\n",
        "    nx, m = X.shape\n",
        "    dj_dw = np.zeros((nx, 1))\n",
        "    dj_db = 0.\n",
        "\n",
        "    for i in range(m):\n",
        "        # non-vectorized weighted sum (z = w1x1 + w2x2... + b)\n",
        "        z_i = 0\n",
        "        for j in range(nx):\n",
        "            z_i += w[j, 0] * X[j, i]\n",
        "        z_i += b\n",
        "\n",
        "        f_wb_i = sigmoid(z_i)\n",
        "        err_i = f_wb_i - y[0, i] # Assuming y is (1, m)\n",
        "\n",
        "        for j in range(nx):\n",
        "            dj_dw[j, 0] += err_i * X[j, i]\n",
        "        dj_db += err_i\n",
        "\n",
        "    return dj_db / m, dj_dw / m"
      ],
      "metadata": {
        "id": "1yYsKg2wXe4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call your function\n",
        "dj_db, dj_dw = compute_gradient_logistic(X, Y, w, b)\n",
        "\n",
        "# Output Results\n",
        "print(f\"Computed dj_db (scalar): {dj_db}\")\n",
        "print(f\"Computed dj_dw shape: {dj_dw.shape}\")\n",
        "print(f\"Computed dj_dw values:\\n{dj_dw}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_5XjyNDr7Ne",
        "outputId": "631006fd-d349-4d79-e273-8940f0992aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed dj_db (scalar): 0.37182828695920767\n",
            "Computed dj_dw shape: (30, 1)\n",
            "Computed dj_dw values:\n",
            "[[6.49955636e+00]\n",
            " [8.03607479e+00]\n",
            " [4.29398820e+01]\n",
            " [3.64337509e+02]\n",
            " [3.82649233e-02]\n",
            " [5.40313747e-02]\n",
            " [5.98689241e-02]\n",
            " [3.27723103e-02]\n",
            " [7.17332259e-02]\n",
            " [2.32996257e-02]\n",
            " [2.26708075e-01]\n",
            " [4.50034521e-01]\n",
            " [1.60947088e+00]\n",
            " [2.70638220e+01]\n",
            " [2.51793751e-03]\n",
            " [1.20072079e-02]\n",
            " [1.55580082e-02]\n",
            " [5.60473080e-03]\n",
            " [7.60743759e-03]\n",
            " [1.50943602e-03]\n",
            " [7.86693140e+00]\n",
            " [1.09059832e+01]\n",
            " [5.26237254e+01]\n",
            " [5.29688182e+02]\n",
            " [5.38635496e-02]\n",
            " [1.39523921e-01]\n",
            " [1.67781250e-01]\n",
            " [6.78655748e-02]\n",
            " [1.20304705e-01]\n",
            " [3.40344635e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent on m examples."
      ],
      "metadata": {
        "id": "-Yjbm-VzXfuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gradient_descent(X, y, w_in, b_in, alpha, num_iters):\n",
        "\n",
        "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
        "    J_history = []\n",
        "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
        "    b = b_in\n",
        "    nx,m=X.shape\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        # Calculate the gradient and update the parameters\n",
        "        dj_db, dj_dw = compute_gradient_logistic(X, y, w, b)\n",
        "\n",
        "        # Update Parameters using w, b, alpha and gradient\n",
        "        w = w - alpha * dj_dw\n",
        "        b = b - alpha * dj_db\n",
        "        y_hat = forward_prop(X, w, b, m, nx)\n",
        "\n",
        "        # Save cost J at each iteration\n",
        "        if i<100000:      # prevent resource exhaustion\n",
        "            cost =  compute_cost(y_hat, y, m)\n",
        "            J_history.append( compute_cost(y_hat,y,m) )\n",
        "\n",
        "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
        "        if i% math.ceil(num_iters / 10) == 0:\n",
        "            print(f\"Iteration {i:4d}: Cost {J_history[-1]}   \")\n",
        "\n",
        "    return w, b, J_history"
      ],
      "metadata": {
        "id": "4rMpg8a8hnYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_breast_cancer()\n",
        "#Real dataset\n",
        "X = dataset.data.T               #(m,nx) transposed->(nx,m)\n",
        "Y = dataset.target.reshape(1, -1)# (m,1)-> (1,m)\n",
        "\n",
        "nx, m = X.shape       #features and no of examples\n",
        "w = np.random.randn(nx, 1) * 0.01 #weights #Shape:(nx,1)\n",
        "b = 0                 #biases #Shape:(1,)\n",
        "y_hat=np.zeros((1,m)) #probability container\n",
        "print(f\"Dataset: Breast Cancer | Features: {nx} | Examples: {m}\")\n",
        "print(f\"X shape: {X.shape}, w shape: {w.shape}\")\n",
        "\n",
        "# 4. Hyperparameters\n",
        "iterations = 1000\n",
        "alpha = 0.1\n",
        "\n",
        "# 5. Run Gradient Descent (Use X and Y, not X_train/y_train)\n",
        "w_final, b_final, J_history = gradient_descent(X, Y, w, b, alpha, iterations)\n",
        "\n",
        "# 6. Show Results\n",
        "print(\"-\" * 30)\n",
        "print(f\"Final Weights (First 3):\\n{w_final[:3]}\")\n",
        "print(f\"Final Bias: {b_final:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs3vhHqas5Ck",
        "outputId": "c4dd56a2-0a3f-44b3-e9d5-39cf16f0ace6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: Breast Cancer | Features: 30 | Examples: 569\n",
            "X shape: (30, 569), w shape: (30, 1)\n",
            "Iteration    0: Cost 21.670198898037278   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2487351055.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration  100: Cost 9.773061045284523   \n",
            "Iteration  200: Cost 3.2171921533266996   \n",
            "Iteration  300: Cost 6.373734059048081   \n",
            "Iteration  400: Cost 2.8529815087587123   \n",
            "Iteration  500: Cost 2.8529843192945012   \n",
            "Iteration  600: Cost 2.8529885350981696   \n",
            "Iteration  700: Cost 2.974385993793302   \n",
            "Iteration  800: Cost 2.9136879670796816   \n",
            "Iteration  900: Cost 2.904519596374347   \n",
            "------------------------------\n",
            "Final Weights (First 3):\n",
            "[[ 28.92525607]\n",
            " [ 39.25652819]\n",
            " [167.98738261]]\n",
            "Final Bias: 3.806147\n"
          ]
        }
      ]
    }
  ]
}